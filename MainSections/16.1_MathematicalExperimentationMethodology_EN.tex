\section{Mathematical Framework for Experimental Analysis}
\label{sec:math_analysis_framework}

This study evaluates the proposed Papoulis--Gerchberg (PG) based LiDAR--stereo fusion pipeline under a structured sweep of algorithmic configurations. Beyond selecting a single ``best'' parameter set, the aim is to characterize how the methodâ€™s internal parameters contribute \emph{independently} and \emph{jointly} to odometric accuracy when trajectories are compared against an RTK-based GNSS reference (ground truth).

\subsection{Problem Definition and Evaluation Setting}

Let the proposed method be governed by two independent control parameters:

\begin{itemize}
    \item $I \in \mathbb{N}$: number of PG refinement iterations,
    \item $H \in \mathbb{N}$: LiDAR upsampling (LU) history size used for temporal conditioning.
\end{itemize}

For each configuration $(I,H)$, an estimated trajectory is produced and evaluated against the RTK reference trajectory using \texttt{evo}. Denote by
\begin{equation}
M(I,H)
\end{equation}
a scalar performance metric computed from this comparison. Depending on the evaluation context, $M$ may represent the APE (e.g., RMSE), the RPE at a specified spatial/temporal scale, a yaw-related error measure, or a derived statistic such as maximum deviation or variance. In all cases, \emph{lower values of $M$ indicate improved performance}.

\paragraph{Trajectory association and alignment policy.}
Because real-world trajectories are sampled asynchronously and may be expressed in different coordinate frames, each comparison is performed after (i) pose association between estimate and reference, and (ii) a fixed alignment policy. Let $\mathcal{A}(\cdot)$ denote the alignment operator applied to the estimated trajectory prior to metric computation, where:
\begin{itemize}
    \item $\mathcal{A}=\mathrm{raw}$: no alignment,
    \item $\mathcal{A}=\mathrm{SE(3)}$: rigid alignment (rotation + translation),
    \item $\mathcal{A}=\mathrm{Sim(3)}$: similarity alignment (rotation + translation + scale).
\end{itemize}
Throughout this analysis, $M(I,H)$ is computed under a \emph{fixed} alignment choice $\mathcal{A}$ (reported explicitly with each metric group), ensuring that all configurations remain directly comparable.

\paragraph{Baseline configuration.}
The baseline configuration is defined as
\begin{equation}
M(0,1),
\end{equation}
corresponding to minimal PG refinement ($I=0$) and minimal temporal conditioning ($H=1$). This baseline serves as a reference point for normalized improvements and interaction analysis.

The primary objective is to quantify how variations in $I$ and $H$ influence $M$, and to identify whether performance gains arise from iteration depth, temporal conditioning, or their interaction.

\subsection{Two-Factor Additive Decomposition Model}

To interpret the performance surface $M(I,H)$, we adopt a two-factor additive decomposition:
\begin{equation}
\boxed{
M(I,H) \;=\; \mu \;+\; \alpha(I) \;+\; \beta(H) \;+\; \gamma(I,H)
}
\label{eq:additive_model}
\end{equation}
where:
\begin{itemize}
    \item $\mu$ is the global mean performance over all tested configurations,
    \item $\alpha(I)$ is the \emph{main effect} attributable to PG iteration count,
    \item $\beta(H)$ is the \emph{main effect} attributable to LU history size,
    \item $\gamma(I,H)$ is the interaction term capturing non-additive behavior.
\end{itemize}

This model separates the average contributions of $I$ and $H$ while explicitly retaining the residual interaction structure. Importantly, this is used as an \emph{effect decomposition} of the measured grid, not as a probabilistic claim.

\subsection{Estimation of Model Components}

Let $\mathcal{I}$ and $\mathcal{H}$ denote the discrete sets of evaluated iteration counts and history sizes, respectively.

\paragraph{Global Mean}
\begin{equation}
\mu \;=\; \frac{1}{|\mathcal{I}||\mathcal{H}|}
\sum_{i \in \mathcal{I}} \sum_{h \in \mathcal{H}} M(i,h).
\end{equation}

\paragraph{Main Effect of PG Iterations}
\begin{equation}
\alpha(i) \;=\; \frac{1}{|\mathcal{H}|}
\sum_{h \in \mathcal{H}} M(i,h) \;-\; \mu.
\end{equation}

\paragraph{Main Effect of LU History}
\begin{equation}
\beta(h) \;=\; \frac{1}{|\mathcal{I}|}
\sum_{i \in \mathcal{I}} M(i,h) \;-\; \mu.
\end{equation}

\paragraph{Interaction Term}
\begin{equation}
\gamma(i,h) \;=\; M(i,h) \;-\; \Big(\mu + \alpha(i) + \beta(h)\Big).
\end{equation}

\paragraph{Identifiability constraints (by construction).}
With the above definitions, the decomposition is uniquely determined and satisfies:
\begin{equation}
\sum_{i\in\mathcal{I}}\alpha(i)=0,
\qquad
\sum_{h\in\mathcal{H}}\beta(h)=0,
\qquad
\sum_{i\in\mathcal{I}}\gamma(i,h)=0,
\qquad
\sum_{h\in\mathcal{H}}\gamma(i,h)=0.
\end{equation}

Large magnitudes of $\gamma(i,h)$ indicate non-additive behavior, meaning the impact of one parameter depends on the level of the other.

\subsection{Marginal (Discrete) Sensitivity Analysis}

To examine incremental changes across the tested grid, marginal finite differences are analyzed.

\paragraph{Iteration Increment (Fixed $H$)}
For a fixed history size $H$, the incremental effect of increasing PG iterations from $I_1$ to $I_2$ is
\begin{equation}
\Delta_I M(I_1\!\to\! I_2 \,;\, H) \;=\; M(I_2,H) \;-\; M(I_1,H).
\end{equation}
A diminishing magnitude of $\Delta_I M$ for increasing $I$ suggests convergence saturation in the refinement process.

\paragraph{History Increment (Fixed $I$)}
Similarly, for fixed iteration count $I$, the incremental effect of increasing LU history from $H_1$ to $H_2$ is
\begin{equation}
\Delta_H M(H_1\!\to\! H_2 \,;\, I) \;=\; M(I,H_2) \;-\; M(I,H_1).
\end{equation}
This reveals whether LU history acts primarily as an optimization driver or as a stabilizing mechanism.

\subsection{Normalized Improvement Ratios}

To express improvements in a scale-independent form, normalized gains are defined relative to the baseline configuration:
\begin{equation}
\Delta M_{\text{total}}(I,H) \;=\; M(0,1) \;-\; M(I,H).
\end{equation}
When $\Delta M_{\text{total}}(I,H)>0$, the configuration $(I,H)$ improves upon the baseline.

The average normalized improvement attributable to iteration depth is summarized as
\begin{equation}
C_I(i) \;=\; \frac{1}{|\mathcal{H}|}
\sum_{h \in \mathcal{H}}
\frac{M(0,1) - M(i,h)}{M(0,1)},
\end{equation}
and the corresponding summary for LU history size is
\begin{equation}
C_H(h) \;=\; \frac{1}{|\mathcal{I}|}
\sum_{i \in \mathcal{I}}
\frac{M(0,1) - M(i,h)}{M(0,1)}.
\end{equation}
These quantities enable direct comparison of the relative importance of $I$ and $H$ even when the absolute scale of $M$ differs across metrics.

\subsection{Superposition Test for Interaction}

To evaluate whether the effects of $I$ and $H$ combine additively, a superposition hypothesis is tested using four canonical configurations:
\begin{itemize}
    \item baseline: $(0,1)$,
    \item iteration-only: $(I,1)$,
    \item history-only: $(0,H)$,
    \item combined: $(I,H)$.
\end{itemize}

Under additive behavior, the expected performance is
\begin{equation}
M_{\text{exp}}(I,H) \;=\;
M(0,1)
+ \Big[M(I,1) - M(0,1)\Big]
+ \Big[M(0,H) - M(0,1)\Big].
\end{equation}

The interaction deviation is defined as
\begin{equation}
\boxed{
\Gamma(I,H) \;=\; M(I,H) \;-\; M_{\text{exp}}(I,H)
}
\end{equation}
where:
\begin{itemize}
    \item $\Gamma(I,H)\approx 0$ indicates additive behavior,
    \item $\Gamma(I,H)<0$ indicates synergistic interaction (combined effect better than additive expectation),
    \item $\Gamma(I,H)>0$ indicates diminishing returns (combined effect worse than additive expectation).
\end{itemize}

\subsection{Metric-Dependent Interpretation}

Different metrics are expected to exhibit different sensitivity profiles with respect to $I$ and $H$. Global measures such as APE often reflect accumulated drift and may respond strongly to refinement depth $\alpha(I)$, whereas local consistency measures (e.g., short-range RPE or variance-based statistics) may respond more strongly to temporal conditioning $\beta(H)$. Orientation-specific errors (e.g., yaw) can also be dominated by downstream SLAM back-end constraints and scene observability, and therefore may not scale linearly with preprocessing parameters.

This framework provides a principled basis for interpreting the experimental grids reported in the next section, enabling systematic comparison of PG-based fusion (PG$\to$GT) and stereo-only baselines (ZED/RTAB-Map$\to$GT) under consistent evaluation conditions.
