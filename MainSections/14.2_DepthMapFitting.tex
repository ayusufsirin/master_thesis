\section{Derinlik Haritası Uyumlama} \label{sec:depth_map_fitting}

Bu adımın amacı, odometri ile yoğunlaştırılmış LiDAR nokta bulutunu kamera düzlemine projekte ederek bir LiDAR derinlik imgesi üretmek ve stereo (ZED) derinlik haritası ile aynı piksel uzayında \textit{örtüşen (overlap)} bölgede tutarlı bir derinlik haritası elde etmektir. Bu işlem, Papoulis--Gerchberg (PG) yinelemelerinden bağımsız olarak, iki sensörün aynı geometri üzerinde hizalanmış tek bir derinlik alanı üretmesini sağlar.

Bu bölümde tanımlanan tüm işlemler deterministik olup, PG tabanlı iteratif iyileştirme yöntemleri için bir başlangıç derinlik alanı üretmektedir.

Derinlik Haritası Uyumlama (DMF) sürecinin üst seviye akışı Şekil~\ref{fig:dmf_overview}'de sunulmaktadır. Bu aşamada LiDAR nokta bulutu ve ZED derinlik haritası, ortak bir kamera geometrisi altında hizalanarak, PG tabanlı yöntemlere başlangıç teşkil eden tutarlı bir derinlik alanı üretilmektedir.

\begin{figure}[H]
    \centering
    \begin{adjustbox}{width=\textwidth}
        \includegraphics{mermaid/dmf_overview.png}
    \end{adjustbox}
    \caption{DMF (Derinlik Haritası Uyumlama) sürecinin üst seviye akışı: LiDAR nokta bulutundan derinlik izdüşümü, ZED derinliğinin ön-işlenmesi, örtüşme bölgesinde ($\Omega_c$) kırpma ve tutarlılık eşiği ($\tau$) ile filtreleme sonrası $D_{\mathrm{fit}}(v,u)$ çıktısının üretilmesi.}
    \label{fig:dmf_overview}
\end{figure}

\subsection{Gösterim ve Girdiler}

ZED stereo kameradan elde edilen derinlik görüntüsü aşağıdaki gibi tanımlanmaktadır:
\begin{equation}
    D_{\text{ZED}}^{\text{orig}}(v,u) \in \mathbb{R} \cup \{\text{NaN}\},
    \label{eq:dmf_zed_orig}
\end{equation}
burada piksel koordinatları
\begin{equation}
    u \in \{0,\dots,W-1\}, \quad v \in \{0,\dots,H-1\}
    \label{eq:dmf_pixel_coords}
\end{equation}
şeklindedir.

LiDAR sensörü tarafından döndürülen üç boyutlu nokta bulutu
\begin{equation}
    \mathcal{P}_{\text{L}}
    =
    \left\{
        \mathbf{p}_k
    =
        \begin{bmatrix}
            x_k \\ y_k \\ z_k
        \end{bmatrix}
        \in \mathbb{R}^3
    \right\}_{k=1}^{N}
    \label{eq:dmf_lidar_cloud}
\end{equation}
olarak tanımlanmaktadır.

Kamera içsel parametreleri (ROS \texttt{CameraInfo} mesajından elde edilmektedir) şu şekildedir:
\begin{equation}
    f_x, f_y \quad \text{(odak uzaklıkları)}, \qquad
    c_x, c_y \quad \text{(ana nokta koordinatları)}.
    \label{eq:dmf_intrinsics}
\end{equation}

Derinlik işlemlerinde kullanılan kırpma bölgesi
\begin{equation}
    \Omega_c =
    \left\{ (v,u) \;\middle|\;
        t \le v < H - b,\
        \ell \le u < W - r
    \right\}
    \label{eq:dmf_roi}
\end{equation}
olarak tanımlanır.

Kırpma parametreleri:
\begin{equation}
\begin{aligned}
    t &= \texttt{MORTAL\_ROWS\_TOP} \\
    b &= \texttt{MORTAL\_ROWS\_BOTTOM} \\
    \ell &= \texttt{MORTAL\_COLUMNS\_LEFT} \\
    r &= \texttt{MORTAL\_COLUMNS\_RIGHT}
\end{aligned}
\label{eq:dmf_crop_params}
\end{equation}
parametreleri görüntüden çıkarılacak bölgeleri ifade etmektedir.

ZED ve LiDAR derinlikleri arasındaki tutarlılık eşiği ise
\begin{equation}
    \tau = \texttt{ZED\_VLP\_DIFF\_MAX}.
    \label{eq:dmf_tau}
\end{equation}
olarak tanımlanmaktadır.

\subsection{LiDAR Kartezyen Gösteriminden Küresel Gösterime Dönüşüm}

Her bir LiDAR noktası $\mathbf{p}_k = (x_k, y_k, z_k)^\top$ için küresel koordinatlar aşağıdaki şekilde tanımlanmaktadır:
\begin{align}
    r_k     &= \sqrt{x_k^2 + y_k^2 + z_k^2}, \\
    \theta_k &= \arctan\!\left( \frac{z_k}{\sqrt{x_k^2 + y_k^2}} \right), \\
    \phi_k   &= \arctan\!\left( \frac{y_k}{x_k} \right),
\end{align}
ve bu gösterim
\begin{equation}
    \mathbf{s}_k =
    \begin{bmatrix}
        r_k \\ \theta_k \\ \phi_k
    \end{bmatrix}
    \label{eq:dmf_spherical}
\end{equation}
şeklinde ifade edilir.

Bu küresel gösterim, uygulama kapsamında açısal filtreleme ve tanılama (diagnostics) amaçlı olarak kullanılmaktadır.

\subsection{LiDAR Noktalarının Kamera Düzlemine Yansıtılması}

LiDAR nokta bulutundan derinlik görüntüsünün elde edilme süreci Şekil~\ref{fig:dmf_projection}'de özetlenmektedir. Bu adımda üç boyutlu LiDAR noktaları, pinhole kamera modeli kullanılarak görüntü düzlemine projekte edilmekte ve z-buffer yaklaşımı ile her piksel için en yakın derinlik değeri seçilmektedir.

\begin{figure}[H]
    \centering
    \begin{adjustbox}{width=\textwidth}
        \includegraphics{mermaid/dmf_projection.png}
    \end{adjustbox}
    \caption{LiDAR nokta bulutundan derinlik görüntüsünün elde edilmesi. Üç boyutlu LiDAR noktaları, pinhole kamera modeli kullanılarak görüntü düzlemine projekte edilmekte ve z-buffer yaklaşımı ile her piksel için en yakın derinlik değeri seçilmektedir.}
    \label{fig:dmf_projection}
\end{figure}


\paragraph*{Eksen Yeniden Eşlemesi.}
LiDAR noktaları öncelikle kamera benzeri bir koordinat sistemine dönüştürülmektedir:
\begin{equation}
    \begin{bmatrix}
        X_k \\ Y_k \\ Z_k
    \end{bmatrix}
    =
    R
    \begin{bmatrix}
        x_k \\ y_k \\ z_k
    \end{bmatrix},
    \qquad
    R =
    \begin{bmatrix}
        0 & -1 & 0 \\
        0 &  0 & -1 \\
        1 &  0 & 0
    \end{bmatrix}.
    \label{eq:dmf_axis_remap}
\end{equation}
Bu dönüşüm sonucunda $Z_k$ ekseni kameraya doğru olan ileri yönü, $X_k$ yatay ekseni ve $Y_k$ ise dikey ekseni temsil etmektedir.

\paragraph*{İğne Deliği (Pinhole) Kamera Modeli.}
Kamera izdüşümü aşağıdaki denklemlerle elde edilmektedir:
\begin{align}
    \tilde{u}_k &= \frac{X_k f_x}{Z_k} + c_x, \\
    \tilde{v}_k &= \frac{Y_k f_y}{Z_k} + c_y,
\end{align}
Bu değerler, piksel indislerine yuvarlanarak dönüştürülür:
\begin{equation}
    u_k = \operatorname{round}(\tilde{u}_k), \qquad
    v_k = \operatorname{round}(\tilde{v}_k).
    \label{eq:dmf_projection}
\end{equation}

Yalnızca kamera görüş alanında kalan ve kameranın önünde bulunan noktalar korunur:
\begin{equation}
    \mathcal{K}
    =
    \left\{ k \;\middle|\;
        0 \le u_k < W,\
        0 \le v_k < H,\
        Z_k > 0,\
        Z_k \text{ sonlu}
    \right\}.
    \label{eq:dmf_valid_proj}
\end{equation}

\paragraph*{LiDAR Derinlik Görüntüsünün Oluşturulması.}
LiDAR derinlik görüntüsü, aynı piksele düşen noktalar arasından en yakın yüzeyin seçilmesiyle elde edilir:
\begin{equation}
    D_{\text{L}}(v,u) =
    \begin{cases}
        \displaystyle
        \min\limits_{k \in \mathcal{K} : (v_k,u_k) = (v,u)} Z_k,
        & \text{eğer böyle bir } k \text{ varsa}, \\[1.2ex]
        \text{NaN}, & \text{aksi halde}.
    \end{cases}
    \label{eq:dmf_lidar_depth}
\end{equation}

Bu işlem, LiDAR nokta bulutundan elde edilen en yakın yüzeye karşılık gelen bir derinlik görüntüsü üretmektedir.

\subsection{ZED Derinlik Haritasının Doldurulması (Inpainting)}

Ham ZED derinlik haritası $D_{\text{ZED}}^{\text{orig}}(v,u)$ geçersiz değerler (NaN veya $\pm\infty$) içerebilmektedir. Bu nedenle bir geçersizlik maskesi şu şekilde tanımlanır:
\begin{equation}
    M(v,u) =
    \begin{cases}
        1, & D_{\text{ZED}}^{\text{orig}}(v,u) \text{ NaN veya } \pm\infty, \\
        0, & \text{aksi halde}.
    \end{cases}
    \label{eq:dmf_invalid_mask}
\end{equation}
kullanılarak yinelemeli bir doldurma işlemi uygulanır.

Yinelemeli doldurma ile:
\begin{equation}
    D^{(t+1)}(v,u)
    =
    \frac{
        \displaystyle
        \sum\limits_{(p,q) \in \mathcal{N}(v,u)}
        D^{(t)}(p,q)\,
        \mathbf{1}_{\{M(p,q) = 0\}}
    }{
        \displaystyle
        \sum\limits_{(p,q) \in \mathcal{N}(v,u)}
        \mathbf{1}_{\{M(p,q) = 0\}}
        + \varepsilon
    }
    \label{eq:dmf_inpainted_zed}
\end{equation}
şeklindedir. Burada $\varepsilon \ll 1$ sıfıra bölmeyi önlemek amacıyla eklenmiştir.

$T$ iterasyon sonunda doldurulmuş ZED derinlik haritası
\begin{equation}
    D_{\text{ZED}}(v,u) = D^{(T)}(v,u)
\end{equation}
olarak elde edilir.

\subsection{Kırpma ve ZED--LiDAR Tutarlılık Filtresi}

ZED ve LiDAR derinlik haritalarının örtüşen görüş hacmi içerisinde birleştirilmesi ve tutarsız ölçümlerin elenmesi süreci Şekil~\ref{fig:dmf_crop} ve Şekil~\ref{fig:dmf_fit_merge}'de gösterilmektedir. Bu aşamada kırpma bölgesi $\Omega_c$ tanımlanmakta, sensörler arası farkı belirli bir eşik $\tau$ değerini aşan LiDAR ölçümleri elenmekte ve DMF çıktısı oluşturulmaktadır.

\begin{figure}[H]
    \centering
    \begin{adjustbox}{width=\textwidth}
        \includegraphics{mermaid/dmf_crop.png}
    \end{adjustbox}
    \caption{DMF kapsamında ZED ve LiDAR derinlik haritalarının örtüşen görüş hacmi içerisinde birleştirilmesi. Kırpma bölgesi $\Omega_c$ tanımlanmakta, sensörler arası farkı eşik değer $\tau$’yı aşan LiDAR ölçümleri elenmekte ve uyumlanmış derinlik haritası oluşturulmaktadır.}
    \label{fig:dmf_crop}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{adjustbox}{width=\textwidth}
        \includegraphics{mermaid/dmf_fit_merge.png}
    \end{adjustbox}
    \caption{DMF kapsamında ZED ve LiDAR derinlik haritalarının örtüşen görüş hacmi içerisinde birleştirilmesi. Kırpma bölgesi $\Omega_c$ tanımlanmakta, sensörler arası farkı eşik değer $\tau$’yı aşan LiDAR ölçümleri elenmekte ve uyumlanmış derinlik haritası oluşturulmaktadır.}
    \label{fig:dmf_fit_merge}
\end{figure}

Derinlik haritaları kırpma bölgesi ile sınırlandırılır:
\begin{align}
    D_{\text{ZED}}^{c}(v,u) &= D_{\text{ZED}}(v,u), \\
    D_{\text{L}}^{c}(v,u)   &= D_{\text{L}}(v,u),
\end{align}
\quad $(v,u) \in \Omega_c$.
\label{eq:dmf_cropped_maps}

ZED ve LiDAR arasındaki tutarsız ölçümler şu koşula göre elenir:
\begin{equation}
    D_{\text{L}}^{c}(v,u) \leftarrow
    \begin{cases}
        D_{\text{L}}^{c}(v,u),
        & \left| D_{\text{ZED}}^{c}(v,u) - D_{\text{L}}^{c}(v,u) \right| \le \tau, \\
        \text{NaN}, & \text{aksi halde}.
    \end{cases}
    \label{eq:dmf_consistency}
\end{equation}

Kırpma bölgesindeki DMF çıktısı:
\begin{equation}
    D_{\text{fit}}^{c}(v,u) = D_{\text{L}}^{c}(v,u).
    \label{eq:dmf_output}
\end{equation}

Bu çıktı, Bölüm~\ref{sec:dynamic_pg} altında tanımlanan yayınlama ve/veya iteratif iyileştirme adımlarına doğrudan girdi olarak kullanılmaktadır.
